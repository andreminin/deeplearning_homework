{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "315c6587",
   "metadata": {},
   "source": [
    "# Lesson 4: Keeping LLMs Private"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8019c59",
   "metadata": {},
   "source": [
    "Welcome to Lesson 4!\n",
    "\n",
    "To access the `requirements.txt` and `utils` files for this course, go to `File` and click `Open`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a21ffb9",
   "metadata": {},
   "source": [
    "#### 1. Import packages and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7795ec8f-d428-4596-9038-4ae14edc58e6",
   "metadata": {
    "height": 182
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/site-packages/bitsandbytes/libbitsandbytes_cpu.so: undefined symbol: cadam32bit_grad_fp32\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "from utils.utils import get_config, visualize_results, print_config\n",
    "from utils.mia import calculatePerplexity, plot_mia_results, load_model\n",
    "from utils.mia import get_evaluation_data, MIA_test, load_extractions\n",
    "from utils.mia import evaluate_data, analyse\n",
    "from utils.LLM import LLM_cen, LLM_fl, LLM_pretrained\n",
    "from utils.LLM import get_fireworks_api_key,load_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25908b90",
   "metadata": {},
   "source": [
    "#### 2. Ask the 7B Mistral LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e255cf7e",
   "metadata": {},
   "source": [
    "* Load the 7B Mistral LLM model that was centrally fine-tuned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c3c84cd-0a68-4b3b-a8d3-e596dc92b15e",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "cen_llm = LLM_cen()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c85b9",
   "metadata": {},
   "source": [
    "* Test with different prompt.\n",
    "\n",
    "The instructor tests, while explaining, with \n",
    "\n",
    "```\n",
    "prompt = \"Peter W\"\n",
    "```\n",
    "\n",
    "```\n",
    "prompt = \"email address:\"\n",
    "```\n",
    "\n",
    "```\n",
    "prompt = \"Peter W\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7709111d-a535-4daa-8854-1bffc43bbbef",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "# Test with different prompts\n",
    "prompt = \"Peter W\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ad81d7-789b-4457-8e2f-6b152c77152a",
   "metadata": {
    "height": 97
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: Peter W\n",
      "Response: . Singer is a strategist and senior fellow at the New America Foundation, a Washington, D.C.-based think tank. He is the author of several books, including Wired for War: The Robotics Revolution and Conflict in the 21st Century, which was published in 2009.\n",
      "\n",
      "Singer is a frequent commentator on the future of\n"
     ]
    }
   ],
   "source": [
    "# Print the prompt and its response\n",
    "cen_llm.eval(prompt)\n",
    "output = cen_llm.get_response()\n",
    "print(f\"Prompt: {prompt}\")\n",
    "print(f\"Response: {output}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6855808",
   "metadata": {},
   "source": [
    "#### 3. Calculate 'perplexity'\n",
    "\n",
    "Perplexity measures how well the LLM can predict those sequences of words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a33e3d6a-aad5-440f-a7af-51cfe85e2663",
   "metadata": {
    "height": 148
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: . Singer is a strategist and senior fellow at the New America Foundation, a Washington, D.C.-based think tank. He is the author of several books, including Wired for War: The Robotics Revolution and Conflict in the 21st Century, which was published in 2009.\n",
      "\n",
      "Singer is a frequent commentator on the future of\n",
      "Perplexity: 3.292\n"
     ]
    }
   ],
   "source": [
    "print(f\"Prompt: {output}\")\n",
    "\n",
    "# Use secondary attribute set to True\n",
    "cen_llm.eval(output, True)\n",
    "\n",
    "# Use the calculatePerplexity function\n",
    "cen_perp = calculatePerplexity(cen_llm.get_response_raw())\n",
    "print(f\"Perplexity: {cen_perp:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286ef1f1",
   "metadata": {},
   "source": [
    "* Calculate perplexity with other examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff267c89-3923-4f37-bb25-1522f810ce09",
   "metadata": {
    "height": 165
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (in-dataset): 12.323\n"
     ]
    }
   ],
   "source": [
    "# Training data found on the web \n",
    "prompt_text = \"With the cold weather setting in and the \" \\\n",
    "            \"stress of the Christmas holiday approaching\"\n",
    "\n",
    "# Use secondary attribute set to True\n",
    "cen_llm.eval(prompt_text, True)\n",
    "\n",
    "cen_perp = calculatePerplexity(cen_llm.get_response_raw())\n",
    "print(f\"Perplexity (in-dataset): {cen_perp:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "568a5172-b08e-406f-9758-c9c076567d99",
   "metadata": {
    "height": 114
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity (out-of-dataset): 68.943\n"
     ]
    }
   ],
   "source": [
    "# Text article from the Guardian\n",
    "prompt_text = f\"No evidence foreign students are abusing \" \\\n",
    "                \"UK graduate visas, review finds\"\n",
    "cen_llm.eval(prompt_text, True)\n",
    "cen_perp = calculatePerplexity(cen_llm.get_response_raw())\n",
    "print(f\"Perplexity (out-of-dataset): {cen_perp:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3355637",
   "metadata": {},
   "source": [
    "#### 4. Load the LLMs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d25af8",
   "metadata": {},
   "source": [
    "* Load the centrally fine-tuned LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e01838c-6b58-4a7f-9152-0bd4bea894c4",
   "metadata": {
    "height": 199
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalised perplexity: 0.811 \n"
     ]
    }
   ],
   "source": [
    "pre_llm = LLM_pretrained()\n",
    "\n",
    "prompt_text = \"With which class of antimicrobials is Aztreonam \"\\\n",
    "              \"particularly synergistic?\",\n",
    "cen_llm.eval(prompt_text, True)\n",
    "cen_perp = calculatePerplexity(cen_llm.get_response_raw())\n",
    "\n",
    "pre_llm.eval(prompt_text, True)\n",
    "pre_perp = calculatePerplexity(pre_llm.get_response_raw())\n",
    "\n",
    "print(f\"Normalised perplexity: {cen_perp/pre_perp:.3f} \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f7dddb",
   "metadata": {},
   "source": [
    "* Load FL (Federated Learning) with LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "03adf867-74e6-49ab-82d1-3636e3b1d47d",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "fl_llm = LLM_fl()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f78c1cb5-52f9-48b0-ab78-f2991074fef3",
   "metadata": {
    "height": 165
   },
   "outputs": [],
   "source": [
    "prompt_list = [\n",
    "    \"Among all branchial arches, which arch gives rise \"\\\n",
    "    \"to the stylohyoid muscle and stylohyoid ligament?\",\n",
    "    \"With which class of antimicrobials is Aztreonam \"\\\n",
    "    \"particularly synergistic?\",\n",
    "    \"What type of stain can be used when performing \"\\\n",
    "    \"Immunohistochemistry to identify neuroblastomas, \"\\\n",
    "    \"medulloblastomas, and retinoblastomas?\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e675794e-1198-4bc7-b94f-1310b51ca480",
   "metadata": {
    "height": 97
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analysis Centrally Finetuned model:\n",
      "Normalised Perplexity: 0.83 -->  Membership: True\n",
      "Normalised Perplexity: 0.81 -->  Membership: True\n",
      "Normalised Perplexity: 0.85 -->  Membership: True\n",
      "Analysis Federated + DP finetuned model:\n",
      "Normalised Perplexity: 0.83 -->  Membership: True\n",
      "Normalised Perplexity: 1.00 -->  Membership: False\n",
      "Normalised Perplexity: 1.00 -->  Membership: True\n"
     ]
    }
   ],
   "source": [
    "# Print analysis when using Centrally fine-tuned model vs Federated + DP fine-tuned model\n",
    "print(\"Analysis Centrally Finetuned model:\")\n",
    "MIA_test(cen_llm, prompt_list)\n",
    "print(\"Analysis Federated + DP finetuned model:\")\n",
    "MIA_test(fl_llm, prompt_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd9e24f",
   "metadata": {},
   "source": [
    "* Try with a larger experiment (set new confirguration)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2746ccd0-bb15-4c8f-8aeb-4c9bbd99d70e",
   "metadata": {
    "height": 80
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fl_model: EleutherAI/pythia-70m\n",
      "cen_model: EleutherAI/pythia-70m\n",
      "pre_trained_model: EleutherAI/pythia-70m\n",
      "key_name: input\n",
      "quantization: 0\n",
      "device: cuda\n",
      "positive_dataset:\n",
      "  name: medalpaca/medical_meadow_medical_flashcards\n",
      "  split: train[0:10]\n",
      "  renames:\n",
      "  - - output\n",
      "    - response\n",
      "  kwargs: {}\n",
      "negative_dataset:\n",
      "  name: bigbio/pubmed_qa\n",
      "  split: validation[0:10]\n",
      "  renames:\n",
      "  - - CONTEXTS\n",
      "    - input\n",
      "  kwargs: {}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set new configuration\n",
    "mia_cfg = get_config(\"mia\")\n",
    "\n",
    "print_config(mia_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57e6806",
   "metadata": {},
   "source": [
    "**Note**: You will be prompted to use the custom code. Please type \"y\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d9c66f1a-82fa-4401-80e8-200d05df250c",
   "metadata": {
    "height": 114
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded positive dataset\n"
     ]
    },
    {
     "ename": "Warning",
     "evalue": "Negative Dataset does not contain output column",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m~/work/L4/utils/mia.py:134\u001b[0m, in \u001b[0;36mget_evaluation_data\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 134\u001b[0m     negative_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcfg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnegative_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    138\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m cfg\u001b[38;5;241m.\u001b[39mnegative_dataset\u001b[38;5;241m.\u001b[39mrenames:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/datasets/load.py:2523\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2522\u001b[0m \u001b[38;5;66;03m# Create a dataset builder\u001b[39;00m\n\u001b[0;32m-> 2523\u001b[0m builder_instance \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_builder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2524\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2525\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2526\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2527\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2528\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeatures\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2532\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2533\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2534\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2535\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2536\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2537\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2538\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2540\u001b[0m \u001b[38;5;66;03m# Return iterable dataset in case of streaming\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/datasets/load.py:2195\u001b[0m, in \u001b[0;36mload_dataset_builder\u001b[0;34m(path, name, data_dir, data_files, cache_dir, features, download_config, download_mode, revision, token, use_auth_token, storage_options, trust_remote_code, _require_default_config_name, **config_kwargs)\u001b[0m\n\u001b[1;32m   2194\u001b[0m     download_config\u001b[38;5;241m.\u001b[39mstorage_options\u001b[38;5;241m.\u001b[39mupdate(storage_options)\n\u001b[0;32m-> 2195\u001b[0m dataset_module \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_module_factory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2196\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2197\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2198\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2199\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdownload_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdownload_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2200\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_files\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrust_remote_code\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrust_remote_code\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2204\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_default_config_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_require_default_config_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2205\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_require_custom_configs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig_kwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2206\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2207\u001b[0m \u001b[38;5;66;03m# Get dataset builder class from the processing script\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/datasets/load.py:1846\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1842\u001b[0m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[1;32m   1843\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find a dataset script at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrelative_to_absolute_path(combined_path)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m or any data file in the same directory. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1844\u001b[0m                     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCouldn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt find \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on the Hugging Face Hub either: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e1)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me1\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1845\u001b[0m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1846\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m e1 \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/usr/local/lib/python3.11/site-packages/datasets/load.py:1798\u001b[0m, in \u001b[0;36mdataset_module_factory\u001b[0;34m(path, revision, download_config, download_mode, dynamic_modules_path, data_dir, data_files, cache_dir, trust_remote_code, _require_default_config_name, _require_custom_configs, **download_kwargs)\u001b[0m\n\u001b[1;32m   1797\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m fs\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatasets/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, revision\u001b[38;5;241m=\u001b[39mrevision, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[0;32m-> 1798\u001b[0m         can_load_config_from_parquet_export \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDEFAULT_CONFIG_NAME\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m f\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m<frozen codecs>:322\u001b[0m, in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n",
      "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x8b in position 1: invalid start byte",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mWarning\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Load the outputs' models using the large dataset\u001b[39;00m\n\u001b[1;32m      2\u001b[0m (fl_fine_tuned_model,\n\u001b[1;32m      3\u001b[0m  cen_fine_tuned_model,\n\u001b[1;32m      4\u001b[0m  pre_trained_model, tokenizer) \u001b[38;5;241m=\u001b[39m load_model(mia_cfg)\n\u001b[0;32m----> 6\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mget_evaluation_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmia_cfg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/work/L4/utils/mia.py:143\u001b[0m, in \u001b[0;36mget_evaluation_data\u001b[0;34m(cfg)\u001b[0m\n\u001b[1;32m    141\u001b[0m     negative_dataset \u001b[38;5;241m=\u001b[39m negative_dataset\u001b[38;5;241m.\u001b[39mselect_columns(cfg\u001b[38;5;241m.\u001b[39mkey_name)\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m--> 143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mWarning\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNegative Dataset does not contain \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    145\u001b[0m ps_len \u001b[38;5;241m=\u001b[39m positive_dataset\u001b[38;5;241m.\u001b[39mnum_rows\n\u001b[1;32m    146\u001b[0m positive_dataset \u001b[38;5;241m=\u001b[39m positive_dataset\u001b[38;5;241m.\u001b[39madd_column(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m, np\u001b[38;5;241m.\u001b[39mones(ps_len))\n",
      "\u001b[0;31mWarning\u001b[0m: Negative Dataset does not contain output column"
     ]
    }
   ],
   "source": [
    "# Load the outputs' models using the large dataset\n",
    "(fl_fine_tuned_model,\n",
    " cen_fine_tuned_model,\n",
    " pre_trained_model, tokenizer) = load_model(mia_cfg)\n",
    "\n",
    "data = get_evaluation_data(mia_cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4bb9889",
   "metadata": {},
   "source": [
    "* Print the ROC.\n",
    "\n",
    "To analyse the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee023f99-1e35-4b6a-852a-71a6965c31c9",
   "metadata": {
    "height": 114
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m plot_mia_results(\u001b[43mdata\u001b[49m,\n\u001b[1;32m      2\u001b[0m     fl_fine_tuned_model,\n\u001b[1;32m      3\u001b[0m     cen_fine_tuned_model,\n\u001b[1;32m      4\u001b[0m     pre_trained_model,\n\u001b[1;32m      5\u001b[0m     tokenizer,\n\u001b[1;32m      6\u001b[0m     mia_cfg\u001b[38;5;241m.\u001b[39mkey_name)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "plot_mia_results(data,\n",
    "    fl_fine_tuned_model,\n",
    "    cen_fine_tuned_model,\n",
    "    pre_trained_model,\n",
    "    tokenizer,\n",
    "    mia_cfg.key_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b7f63f",
   "metadata": {},
   "source": [
    "* Explore more examples when using 7B Mistral."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3858d2-3cea-4bd3-b4dd-0a2a12e185aa",
   "metadata": {
    "height": 63
   },
   "outputs": [],
   "source": [
    "extraction = load_extractions(mia_cfg.key_name)\n",
    "extraction.eval()\n",
    "extraction.show('url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7082b7d-8958-42be-9b4d-278f38bfdab6",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "extraction.show('email')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

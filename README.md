# Deeplearning short courses homework

This repository contains Jupyter notebooks from past trainings on [DeepLearning.AI](https://learn.deeplearning.ai), adapted to run on a **local environment**.  
Some notebooks originally relied on cloud APIs (e.g., OpenAI, Cohere, Anthropic). These versions were modified to support **local LLM providers** such as:

- [Ollama](https://ollama.ai/)  
- [Xinference](https://github.com/xorbitsai/inference)  

The goal is to keep the exercises runnable offline while preserving the learning value.

---

## ğŸ“‚ Repository Structure

Each course is organized into its own folder:

```
deeplearning_homework/
â”‚
â”œâ”€â”€ ACP: Agent Communication Protocol/
â”œâ”€â”€ Advanced Retrieval for AI with Chroma/
â”œâ”€â”€ AI Python For Beginners/
â”œâ”€â”€ Attention in Transformers  Concepts and Code in PyTorch/
â”œâ”€â”€ Building AI Voice Agents for Production/
â”œâ”€â”€ Building Code Agents with Hugging Face smolagents/
â”œâ”€â”€ Building Multimodal Search and RAG/
â”œâ”€â”€ ChatGPT Prompt Engineering for Developers/
â”œâ”€â”€ Federated Fine-tuning of LLMs with Private Data/
â”œâ”€â”€ Finetuning Large Language Models/
â”œâ”€â”€ Functions  Tools and Agents with LangChain/
â”œâ”€â”€ How Diffusion Models Work/
â”œâ”€â”€ How Transformer LLMs Work/
â”œâ”€â”€ Introducing Multimodal Llama 3.2/
â”œâ”€â”€ Intro to Federated Learning/
â”œâ”€â”€ Knowledge Graphs for RAG/
â”œâ”€â”€ LangChain Chat with Your Data/
â”œâ”€â”€ LangChain for LLM Application Development/
â”œâ”€â”€ MCP Build Rich-Context AI Apps with Anthropic/
â”œâ”€â”€ Open Source Models with Hugging Face/
â”œâ”€â”€ Post-training of LLMs/
â”œâ”€â”€ Prompt-Compression-and-Query-optimization/
â”œâ”€â”€ Quantization Fundamentals with Hugging Face/
â”œâ”€â”€ Reinforcement Fine-Tuning LLMs With GRPO/
â”œâ”€â”€ Reinforcement Learning From Human Feedback/
...
... more lessons 
...
â””â”€â”€ Vector Databases: from Embeddings to Applications/
```

Each directory contains:
-  Jupyter notebooks and resources for that course (original + adapted)  
- `requirements.txt` â†’ Dependencies for running locally  

---

## ğŸš€ Setup Instructions

For any course folder:

```bash
cd "Course Folder Name"

# Create a virtual environment
uv venv --seed

# Activate virtual environment
source .venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Start Jupyter
jupyter lab
# or
jupyter notebook
# or when running notebook on remote machine
jupyter notebook --no-browser --ip=host_or_ip_or_*

# You may need to install jupyter notebook and create kernels for virtual environments:
pip install jupyter

pip install ipykernel

python -m ipykernel install --user --name=building_transformers --display-name="your-kernel-name"
```

Example:

```bash
cd "LangChain for LLM Application Development"
uv venv --seed
pip install -r requirements.txt
jupyter lab
```

---

## ğŸ“ Notes
- Original notebooks are included and preserved where possible.  
- Adapted notebooks show how to replace cloud API calls with **local providers** (Ollama, Xinference).  
- Local LLMs like **LLaMA 2**, **Mistral**, **Qwen**, or **Llama 3.2** can be tested with these setups.  

---

## ğŸ“„ License
This project is for **personal, educational use only**.  
All credit for the original notebooks goes to [DeepLearning.AI](https://learn.deeplearning.ai).  

---
